# oneDNN binary size reduction through build system.

## Problem Statement.
Some oneDNN customers, including the OpenVINO toolkit, have requirements for
their applications to fit a specific disk space quota. Currently, applications
linked statically with oneDNN exceed this quota a lot due to the library
implementation way. Our experiments show that binary size of statically linked
end-user application may take up to 64 MB [1]. Further analysis revealed
several spots that contribute most:

* The implementation of threading layer through templates. This is TBB specific,
  OMP doesn't suffer from it. Takes ~14 MB.
* The implementation of reorders through templates of plain C code and their
  multiple instantiations. Takes ~9 MB.
* The implementation of GEMM autogenerated JIT-ted kernels. Takes ~14 MB.
* The implementation of convolution kernels apart from GEMM. Takes ~8 MB.
* Rest functionality takes ~12 MB + ~2 MB of core API.

## Background
The reason why static linking can't solve the problem itself is the way library
API is implemented. The call to `dnnl_primitive_desc_create` (which is also used
underneath the correspondent C++ API) relies on statically defined
implementation lists which contain all primitives at once. That means that if
user calls the function (which is an essential part of the API), they get the
full library in their application. And there are not many choices how to deal
with such problem. One is to switch off implementations in compile time (this
RFC proposal) or using a different API which would separate things on different
levels (at least on primitive one).

## Proposal
To control the size, the proposal is to utilize the power of build system and
let the user specify set of desired options. The idea is to have two sets of
macros, one is external and would be defined by the build system based on user
choices. This external set would control another set - internal - which lives
inside the library and modifies implementation lists. Each primitive would get
several macros to switch on/off certain implementations in compile time. Further
optimizations of disk space will be provided by linker which shouldn't include
unused code inside the end-user application unless certain scenario happens [2].

As a part of this proposal, there are only two possible options to specify right
now:
* Propagation kind: `training` (the default) or `inference` (a subset of
  `training`). Usage example, which enables `inference` only:
  - -DNNL_ENABLE_PROP_KIND=INFERENCE
* Primitives. Usage example, which enables only convolution and matmul:
  - -DDNNL_ENABLE_PRIMITIVES=CONVOLUTION;MATMUL

This list may be extended in future upon request with data types and, possibly,
ISA, if it's proven to help with further size reduction with minimal amount of
enabling efforts and maintenance cost.

Pros:
1. No API changes and transparent enabling for the end-user.
2. Simple enabling.

Cons:
1. Can't be fully automated and relies on the way the code is written and
   structured.
2. May require semi-rocket-science validation.

## Additional Comments
[1] oneDNN v2.2 + gcc 4.8.5 + release mode + standard linker +
    TBB threading (2017.2) + c++11 + native optimizations on AVX2.

[2] Certain scenario mentioned is the following. Assume linker uses
implementation list as the primary entry point to fill the binary with
implementations code. It needs to include all code into the binary which was
referenced from the list. It finds object files (that is, translation units) and
includes necessary code and some unnecessary code too. Unnecessary code
can be either of:
* Instantiations of templated classes.
* Specializations of templated classes or class members.
* Non-templated class methods definitions.
* ... (maybe something else we don't experience in the library) ...

This behavior can't be changed or influenced externally.

## Implementation Details

Main mechanism:

```cmake
# options.cmake:

foreach(impl in ${DNNL_IMPLS})
    foreach(prop in ${DNNL_PROPS})
        string(TOUPPER ${impl} uimpl)
        string(TOUPPER ${prop} uprop)
        ...
        set(BUILD_${uimpl}_${uprop} TRUE)
    endforeach()
endforeach()
```

```cpp
// src/common/impl_registration.hpp (new header):

#if BUILD_CONVOLUTION_FWD
#define REGISTER_CONVOLUTION_FWD(...) __VA_ARGS__
#else
#define REGISTER_CONVOLUTION_FWD(...)
#endif

#if BUILD_CONVOLUTION_BWD
#define REGISTER_CONVOLUTION_BWD(...) __VA_ARGS__
#else
#define REGISTER_CONVOLUTION_BWD(...)
#endif
```

```cpp
// src/cpu/cpu_convolution_list.cpp:
const std::map<conv_impl_key_t, std::vector<pd_create_f>> impl_list_map {
    // FWD fp
    {{forward, f32, f32, f32}, {
        REGISTER_CONVOLUTION_FWD(CPU_INSTANCE_X64(ip_convolution_fwd_t))
        ...
        REGISTER_CONVOLUTION_FWD(CPU_INSTANCE(ref_fused_convolution_fwd_t))
        nullptr,
    }},
```

Additionally, to overcome some of [2], instantiations in separate translations
units should be wrapped as well:

```cpp
// src/cpu/ref_convolution.cpp:

REGISTER_CONVOLUTION_FWD(template struct ref_convolution_fwd_t<f32>);
...
```

To resolve unnecessary code inclusions, it is enough to separate, i.e. for
propagation kind, forward implementation details from backward into different
translation units. Then linker will not include anything from backward if it was
switched off by user. This is likely not the cheapest but straightforward
solution which allows to leave the code written itself intact.

## Open questions
* GEMM auto-gen kernel take a lot of disk space and the plan is to replace them
  with corresponding BRGEMM implementation. The problem is the final transition
  may happen in 8+ month which is a long period. There is an option to disable
  those in compile time as well, but this might hit performance. If new level
  of performance without those kernels is acceptable, we may add a switch to
  remove them in compile time as well alongside other primitives. Should we
  consider doing it?

* Is it reasonable to enable data type option at all?
  - Likely oneDNN team needs to experiment with shrinking data type templates
    and measure the impact on binary size first to have a proper answer.

* If enabling ISA as an option:
  - What does it mean to enable current ISA - use implementations which support
    only this ISA, or follow some comparison system and include all up to
    selected?
    - Requires OpenVINO feedback.
